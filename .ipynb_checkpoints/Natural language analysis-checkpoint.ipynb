{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 25531: expected 18 fields, saw 19\\n'\n",
      "b'Skipping line 231615: expected 18 fields, saw 19\\n'\n"
     ]
    }
   ],
   "source": [
    "# Adds logging\n",
    "import logging\n",
    "logger = logging.getLogger('natural_language_analysis')\n",
    "hdlr = logging.FileHandler('natural_language_analysis.log')\n",
    "formatter = logging.Formatter('%(asctime)s %(levelname)s %(message)s')\n",
    "hdlr.setFormatter(formatter)\n",
    "logger.addHandler(hdlr) \n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "def cell_log(number, name=None):\n",
    "    if name == None:\n",
    "        logger.info(\"Cell no: {}\".format(number))\n",
    "    else:\n",
    "        logger.info(\"Cell name: {} number {}\".format(name, number))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data_imported = pd.read_csv(\"data/kickstart_join_result.csv\", sep=\"\\t\", error_bad_lines=False, encoding=\"utf-8\" )\n",
    "data_imported.head(10)\n",
    "cell_log(0, \"imports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's a nan\n",
      "That's a nan\n",
      "That's a nan\n",
      "248408\n",
      "248411\n"
     ]
    }
   ],
   "source": [
    "cell_log(1)\n",
    "def remove_those_nan(string):\n",
    "    if isinstance(string, float):\n",
    "        if np.isnan(string):\n",
    "            print(\"That's a nan\")\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "#print(data_imported[data_imported[\"blurb\"].apply(is_not_ascii)])\n",
    "data_imported_nonan = data_imported.copy()\n",
    "data_imported_nonan.loc[:, \"blurb\"] = data_imported_nonan.blurb.dropna(how=\"any\")\n",
    "data_imported_nonan = data_imported_nonan[data_imported_nonan.blurb.apply(remove_those_nan)]\n",
    "print(data_imported_nonan.shape[0])\n",
    "print(data_imported.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals for this notebook\n",
    "<ul>\n",
    "    <li>Use a naive bayes algorithm to predict the successfulness based on the blurb</li>\n",
    "    <ul>\n",
    "        <li>If this works I will attempt to extract the most sensitive words for this</li>\n",
    "        <li>I would also give it a try to see if I can run an algorithm on the categories</li>\n",
    "    </ul>\n",
    "    <li>I would also like to give a try on what categories each belongs to</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "cell_log(2, \"imports for nlp\")\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Bring in the stemmer and grab the stopwords\n",
    "import nltk\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "from nltk import word_tokenize\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download('punkt')\n",
    "\n",
    "import re\n",
    "\n",
    "# Split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Encode y\n",
    "Encoder = LabelEncoder()\n",
    "y_encode = Encoder.fit_transform(data_imported_nonan.state)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_imported_nonan.blurb, \n",
    "                                                    y_encode, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_log(3, \"tokenizer\")\n",
    "stemmer = EnglishStemmer(ignore_stopwords=True)\n",
    "def stem_tokenizer(text):\n",
    "    words = word_tokenize(text)\n",
    "    to_return = []\n",
    "    for word in words:\n",
    "        to_return.append(stemmer.stem(word))\n",
    "    logger.debug(\"Vocabulary: {}\".format(' '.join(to_return)))\n",
    "    return to_return\n",
    "\n",
    "vect = HashingVectorizer(decode_error='ignore', n_features=2**25, tokenizer=stem_tokenizer, alternate_sign=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_log(4)\n",
    "# Obtain the vectorized data\n",
    "X_train_vect = vect.transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_log(5, \"First bayes\")\n",
    "bayes_clf = MultinomialNB()\n",
    "param_range = [0.001, 0.003, 0.01, 0.03, 0.1, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 1, 2, 3, 4, 10, 100, 1.5, 3.5, 2.5]\n",
    "param_grid = [{'alpha': param_range}]\n",
    "\n",
    "# Searches for best parameters\n",
    "logger.info(\"In we go\")\n",
    "gs = GridSearchCV(estimator=bayes_clf,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='roc_auc',\n",
    "                  cv=10,\n",
    "                  n_jobs=-1)\n",
    "gs.fit(X_train_vect, y_train)\n",
    "logger.info(gs.best_score_)\n",
    "logger.info(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_log(6, \"First bayes classification\")\n",
    "X_test_vect = vect.transform(X_test)\n",
    "y_pred = gs.best_estimator_.predict(X_test_vect)\n",
    "logger.info(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So Naive Bayes Failed....\n",
    "This isn't horrible, the fact that it failed can be due to two factors:\n",
    "1. The premise that $P(A \\cap B ) = P(A)P(B)$ is untrue, this is most likely\n",
    "2. The hasing vectorizer, (which upon collision makes the numbers negative) I had to stop, this leads to the hashing vectorizer not giving the right count for each word.\n",
    "I can try to fix this by using TF-IDF, I doubt it will however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_log(7)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_log(8)\n",
    "vect = TfidfVectorizer(tokenizer=stem_tokenizer, min_df=100, ngram_range=(1, 2))\n",
    "X_train_vect = vect.fit_transform(X_train)\n",
    "\n",
    "logger.info(\"Word tokenizer results: {}\\n Word tokenizer count {}\".format(vect.vocabulary_, X_train_vect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_log(9, \"MulinomialNB: alpha train\")\n",
    "param_range = [0.001, 0.003, 0.01, 0.03, 0.1, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 1, 2, 3, 4, 10, 100, 1.5, 3.5, 2.5]\n",
    "param_grid = [{'alpha': param_range}]\n",
    "# Searches for best parameters\n",
    "logger.info(\"In we go\")\n",
    "bayes_clf = MultinomialNB()\n",
    "gs = GridSearchCV(estimator=bayes_clf,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='roc_auc',\n",
    "                  cv=10,\n",
    "                  n_jobs=-1)\n",
    "gs.fit(X_train_vect, y_train)\n",
    "logger.info(gs.best_score_)\n",
    "logger.info(gs.best_params_)\n",
    "X_test_vect = vect.transform(X_test)\n",
    "y_pred = gs.best_estimator_.predict(X_test_vect)\n",
    "logger.info(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# That didn't go great. On to better algorithms!\n",
    "I will give logistic regression a chance, it is usually a pretty good algorithm in general. I could also try SVC. For selecting algorithms, it is usually better to try with a k-folds approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_log(10)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_log(11, \"Generate new classifiers\")\n",
    "forest = RandomForestClassifier(n_jobs=-1)\n",
    "svc = SVC()\n",
    "log_reg = LogisticRegression(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_log(12, \"Setup scoring\")\n",
    "# I will stick with the tf-idf\n",
    "def fit_return_best_model(estimator, param_grid, n_jobs=1):\n",
    "    gs = GridSearchCV(estimator=estimator, \n",
    "                      param_grid=param_grid,\n",
    "                      n_jobs=n_jobs,\n",
    "                      return_train_score = True,\n",
    "                      cv=3)\n",
    "    gs.fit(X_train_vect, y_train)\n",
    "    estimator = gs.best_estimator_\n",
    "    logger.info(gs.best_params_)\n",
    "    return gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_log(13, \"Params\")\n",
    "forest_pg = {\"n_estimators\":[10, 100, 300], \"max_depth\": [10, 100, 150, None]}\n",
    "svc_pg = {\"C\": [0.1, 1.0, 10.0, 100.0], \"max_iter\":[300], \"gamma\": [0.001, 0.01, 0.1, 1.0, 10.0], \"kernel\":[\"rbf\"]}\n",
    "log_pg = {\"C\": [0.1, 1.0, 10.0, 100.0], \"max_iter\": [100, 300]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([7.97413031e-01, 6.30892936e+00, 3.15896173e+01, 6.87134093e+01,\n",
       "        5.13363895e+02, 1.26000599e+03, 1.04533684e+02, 7.33956755e+02,\n",
       "        1.45842115e+03, 1.59863864e+02, 9.39351279e+02, 1.28711966e+03]),\n",
       " 'std_fit_time': array([  0.25798916,   0.83448468,   0.5537277 ,   0.44119494,\n",
       "          1.78828608,  12.56800008,   2.74674405,   4.06843871,\n",
       "         10.7118102 ,   0.72567371,  19.34078841, 102.09317185]),\n",
       " 'mean_score_time': array([0.30627767, 1.99882452, 4.80826688, 1.92491484, 5.93891319,\n",
       "        7.42606115, 2.23810109, 6.6667645 , 5.95167271, 2.64628943,\n",
       "        6.64320135, 3.16917833]),\n",
       " 'std_score_time': array([0.02940879, 0.19256987, 0.21828859, 0.07657123, 0.38232042,\n",
       "        0.23759083, 0.1432155 , 0.18600764, 0.41217302, 0.05358285,\n",
       "        0.40640357, 1.10644071]),\n",
       " 'param_max_depth': masked_array(data=[10, 10, 10, 100, 100, 100, 150, 150, 150, None, None,\n",
       "                    None],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[10, 100, 300, 10, 100, 300, 10, 100, 300, 10, 100, 300],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'max_depth': 10, 'n_estimators': 10},\n",
       "  {'max_depth': 10, 'n_estimators': 100},\n",
       "  {'max_depth': 10, 'n_estimators': 300},\n",
       "  {'max_depth': 100, 'n_estimators': 10},\n",
       "  {'max_depth': 100, 'n_estimators': 100},\n",
       "  {'max_depth': 100, 'n_estimators': 300},\n",
       "  {'max_depth': 150, 'n_estimators': 10},\n",
       "  {'max_depth': 150, 'n_estimators': 100},\n",
       "  {'max_depth': 150, 'n_estimators': 300},\n",
       "  {'max_depth': None, 'n_estimators': 10},\n",
       "  {'max_depth': None, 'n_estimators': 100},\n",
       "  {'max_depth': None, 'n_estimators': 300}],\n",
       " 'split0_test_score': array([0.5900548 , 0.6011956 , 0.60259952, 0.61905409, 0.65176698,\n",
       "        0.65493713, 0.61820872, 0.65265764, 0.65667316, 0.6123213 ,\n",
       "        0.65185755, 0.65659768]),\n",
       " 'split1_test_score': array([0.58864467, 0.60079708, 0.60321246, 0.62350171, 0.65034268,\n",
       "        0.6538148 , 0.62046738, 0.65114278, 0.65544519, 0.61654237,\n",
       "        0.65081066, 0.65638115]),\n",
       " 'split2_test_score': array([0.58575505, 0.60036835, 0.60181761, 0.61973702, 0.65051856,\n",
       "        0.65284341, 0.62015972, 0.65237542, 0.65658731, 0.61911807,\n",
       "        0.65169608, 0.65630048]),\n",
       " 'mean_test_score': array([0.58815153, 0.60078701, 0.6025432 , 0.62076427, 0.65087608,\n",
       "        0.65386512, 0.61961193, 0.65205861, 0.65623522, 0.61599388,\n",
       "        0.65145477, 0.65642644]),\n",
       " 'std_test_score': array([0.00178967, 0.0003378 , 0.00057084, 0.00195564, 0.00063405,\n",
       "        0.0008555 , 0.00100015, 0.00065776, 0.00055974, 0.00280174,\n",
       "        0.0004602 , 0.00012549]),\n",
       " 'rank_test_score': array([12, 11, 10,  7,  6,  3,  8,  4,  2,  9,  5,  1], dtype=int32),\n",
       " 'split0_train_score': array([0.59872587, 0.6121993 , 0.61557332, 0.91741582, 0.97756693,\n",
       "        0.98088057, 0.96081007, 0.993101  , 0.9939011 , 0.98318275,\n",
       "        0.99846018, 0.99846018]),\n",
       " 'split1_train_score': array([0.6014915 , 0.61656502, 0.61867848, 0.9160125 , 0.97694061,\n",
       "        0.98106941, 0.95884031, 0.99296519, 0.99387851, 0.9834697 ,\n",
       "        0.99843755, 0.99843755]),\n",
       " 'split2_train_score': array([0.59720723, 0.61588859, 0.61699815, 0.91396762, 0.97599728,\n",
       "        0.97953731, 0.9589312 , 0.99257274, 0.99378043, 0.9828056 ,\n",
       "        0.99838472, 0.99839227]),\n",
       " 'mean_train_score': array([0.59914154, 0.6148843 , 0.61708332, 0.91579865, 0.97683494,\n",
       "        0.98049576, 0.95952719, 0.99287964, 0.99385335, 0.98315268,\n",
       "        0.99842748, 0.99843   ]),\n",
       " 'std_train_score': array([1.77356941e-03, 1.91856171e-03, 1.26910715e-03, 1.41582050e-03,\n",
       "        6.45148604e-04, 6.82101206e-04, 9.07886925e-04, 2.23982574e-04,\n",
       "        5.23797766e-05, 2.71950436e-04, 3.16164669e-05, 2.82327869e-05])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_log(14, \"Forest training\")\n",
    "gs = GridSearchCV(estimator=forest, \n",
    "                  param_grid=forest_pg,\n",
    "                  n_jobs=-1,\n",
    "                  return_train_score=True,\n",
    "                  cv=3)\n",
    "gs.fit(X_train_vect, y_train)\n",
    "estimator = gs.best_estimator_\n",
    "logger.info(gs.best_params_)\n",
    "logger.info(gs.cv_results_)\n",
    "gs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([20.87523071, 21.1697851 , 20.24706546, 21.19583861, 19.66412592,\n",
       "        20.63612151, 20.17576877, 19.34408275, 18.10261766, 18.17180912,\n",
       "        20.1820941 , 19.82349141, 19.18231058, 16.95996038, 17.47174017,\n",
       "        18.92060057, 20.03993336, 17.29694867, 17.13173135, 16.55204344]),\n",
       " 'std_fit_time': array([2.03600352, 2.08406011, 2.58865191, 2.07477121, 1.61075814,\n",
       "        1.53934527, 1.3614882 , 2.36957229, 1.50939254, 0.63023183,\n",
       "        1.09978926, 0.4276369 , 0.56362476, 2.35314076, 0.2115574 ,\n",
       "        0.78977952, 1.12394386, 1.96730759, 1.96828418, 0.62362278]),\n",
       " 'mean_score_time': array([8.84462969, 8.85943921, 8.51179187, 8.85028982, 7.98412665,\n",
       "        8.19784896, 7.94473767, 7.52394978, 7.14724469, 7.40476068,\n",
       "        8.58941205, 7.8695004 , 7.65068849, 6.76215172, 7.01587081,\n",
       "        8.12741764, 7.33620834, 6.46826212, 5.65333581, 6.8031679 ]),\n",
       " 'std_score_time': array([0.99186768, 1.11887186, 1.36358507, 1.25919129, 0.99486159,\n",
       "        0.51658757, 1.12781998, 1.46684531, 0.9976468 , 0.24750232,\n",
       "        0.61231812, 0.19108495, 0.51501302, 1.14085661, 0.40783313,\n",
       "        0.58750906, 0.52727355, 2.02206052, 0.16885221, 0.48633662]),\n",
       " 'param_C': masked_array(data=[0.1, 0.1, 0.1, 0.1, 0.1, 1.0, 1.0, 1.0, 1.0, 1.0, 10.0,\n",
       "                    10.0, 10.0, 10.0, 10.0, 100.0, 100.0, 100.0, 100.0,\n",
       "                    100.0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_gamma': masked_array(data=[0.001, 0.01, 0.1, 1.0, 10.0, 0.001, 0.01, 0.1, 1.0,\n",
       "                    10.0, 0.001, 0.01, 0.1, 1.0, 10.0, 0.001, 0.01, 0.1,\n",
       "                    1.0, 10.0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel': masked_array(data=['rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_iter': masked_array(data=[300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
       "                    300, 300, 300, 300, 300, 300, 300, 300, 300],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.1, 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 300},\n",
       "  {'C': 0.1, 'gamma': 0.01, 'kernel': 'rbf', 'max_iter': 300},\n",
       "  {'C': 0.1, 'gamma': 0.1, 'kernel': 'rbf', 'max_iter': 300},\n",
       "  {'C': 0.1, 'gamma': 1.0, 'kernel': 'rbf', 'max_iter': 300},\n",
       "  {'C': 0.1, 'gamma': 10.0, 'kernel': 'rbf', 'max_iter': 300},\n",
       "  {'C': 1.0, 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 300},\n",
       "  {'C': 1.0, 'gamma': 0.01, 'kernel': 'rbf', 'max_iter': 300},\n",
       "  {'C': 1.0, 'gamma': 0.1, 'kernel': 'rbf', 'max_iter': 300},\n",
       "  {'C': 1.0, 'gamma': 1.0, 'kernel': 'rbf', 'max_iter': 300},\n",
       "  {'C': 1.0, 'gamma': 10.0, 'kernel': 'rbf', 'max_iter': 300},\n",
       "  {'C': 10.0, 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 300},\n",
       "  {'C': 10.0, 'gamma': 0.01, 'kernel': 'rbf', 'max_iter': 300},\n",
       "  {'C': 10.0, 'gamma': 0.1, 'kernel': 'rbf', 'max_iter': 300},\n",
       "  {'C': 10.0, 'gamma': 1.0, 'kernel': 'rbf', 'max_iter': 300},\n",
       "  {'C': 10.0, 'gamma': 10.0, 'kernel': 'rbf', 'max_iter': 300},\n",
       "  {'C': 100.0, 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 300},\n",
       "  {'C': 100.0, 'gamma': 0.01, 'kernel': 'rbf', 'max_iter': 300},\n",
       "  {'C': 100.0, 'gamma': 0.1, 'kernel': 'rbf', 'max_iter': 300},\n",
       "  {'C': 100.0, 'gamma': 1.0, 'kernel': 'rbf', 'max_iter': 300},\n",
       "  {'C': 100.0, 'gamma': 10.0, 'kernel': 'rbf', 'max_iter': 300}],\n",
       " 'split0_test_score': array([0.53042586, 0.5228326 , 0.52124753, 0.5091104 , 0.51813777,\n",
       "        0.53042586, 0.53468291, 0.52938424, 0.52589708, 0.51795661,\n",
       "        0.53949851, 0.51936054, 0.52055312, 0.52973144, 0.51822834,\n",
       "        0.52397989, 0.51863593, 0.5317392 , 0.52278731, 0.51822834]),\n",
       " 'split1_test_score': array([0.5275505 , 0.52729386, 0.51053712, 0.53846502, 0.48162797,\n",
       "        0.52810905, 0.53681954, 0.52104405, 0.51918722, 0.51782857,\n",
       "        0.53076598, 0.52762598, 0.50831799, 0.52554271, 0.48334893,\n",
       "        0.53011684, 0.51237885, 0.52003261, 0.52198001, 0.48446605]),\n",
       " 'split2_test_score': array([0.52141423, 0.52802645, 0.53791458, 0.52346734, 0.5177609 ,\n",
       "        0.52745279, 0.53053245, 0.52668287, 0.52728673, 0.51794206,\n",
       "        0.51732311, 0.53522743, 0.51517942, 0.5244486 , 0.48273728,\n",
       "        0.50346462, 0.52946061, 0.52556574, 0.53454809, 0.48242025]),\n",
       " 'mean_test_score': array([0.52646357, 0.52605094, 0.52323299, 0.52368085, 0.50584221,\n",
       "        0.52866258, 0.53401165, 0.52570373, 0.52412367, 0.51790908,\n",
       "        0.52919598, 0.52740457, 0.51468353, 0.52657428, 0.4947717 ,\n",
       "        0.51918722, 0.52015841, 0.52577921, 0.52643841, 0.49503839]),\n",
       " 'std_test_score': array([3.75840438e-03, 2.29530625e-03, 1.12645930e-02, 1.19849719e-02,\n",
       "        1.71227479e-02, 1.27529865e-03, 2.61020418e-03, 3.47455743e-03,\n",
       "        3.53639645e-03, 5.72404153e-05, 9.12088533e-03, 6.47952281e-03,\n",
       "        5.00728164e-03, 2.27672296e-03, 1.65884203e-02, 1.13962437e-02,\n",
       "        7.05617985e-03, 4.78159862e-03, 5.74380606e-03, 1.64192095e-02]),\n",
       " 'rank_test_score': array([ 6,  8, 13, 12, 18,  3,  1, 10, 11, 16,  2,  4, 17,  5, 20, 15, 14,\n",
       "         9,  7, 19], dtype=int32),\n",
       " 'split0_train_score': array([0.53271741, 0.52451258, 0.52271612, 0.51419427, 0.52089702,\n",
       "        0.53271741, 0.53586498, 0.52916978, 0.52756957, 0.52104798,\n",
       "        0.54012213, 0.52356151, 0.522384  , 0.5349592 , 0.52080644,\n",
       "        0.52452768, 0.51768151, 0.53322313, 0.5252221 , 0.52080644]),\n",
       " 'split1_train_score': array([0.52862987, 0.53173213, 0.51274116, 0.53921228, 0.48426225,\n",
       "        0.53267564, 0.53808007, 0.52069684, 0.52023641, 0.52108934,\n",
       "        0.53341536, 0.5301093 , 0.50826515, 0.527158  , 0.48651158,\n",
       "        0.53111319, 0.51720208, 0.52233477, 0.52361795, 0.48789288]),\n",
       " 'split2_train_score': array([0.52199872, 0.52508586, 0.53844586, 0.52929011, 0.5207382 ,\n",
       "        0.52653508, 0.53154697, 0.52583311, 0.53162245, 0.52107786,\n",
       "        0.52059478, 0.5360003 , 0.51726611, 0.52671623, 0.48739103,\n",
       "        0.50776314, 0.53060346, 0.52815036, 0.53944975, 0.48702117]),\n",
       " 'mean_train_score': array([0.527782  , 0.52711019, 0.52463438, 0.52756555, 0.50863249,\n",
       "        0.53064271, 0.53516401, 0.52523324, 0.52647614, 0.52107173,\n",
       "        0.53137742, 0.52989037, 0.51597175, 0.52961114, 0.49823635,\n",
       "        0.52113467, 0.52182902, 0.52790275, 0.52942993, 0.4985735 ]),\n",
       " 'std_train_score': array([4.41676641e-03, 3.27657664e-03, 1.05812003e-02, 1.02860990e-02,\n",
       "        1.72324831e-02, 2.90458312e-03, 2.71279434e-03, 3.48497405e-03,\n",
       "        4.71219573e-03, 1.74310678e-05, 8.10120049e-03, 5.08047310e-03,\n",
       "        5.83621043e-03, 3.78594665e-03, 1.59635045e-02, 9.82990507e-03,\n",
       "        6.20755678e-03, 4.44860020e-03, 7.11528232e-03, 1.57250939e-02])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_log(15, \"SVC\")\n",
    "gs_svc = fit_return_best_model(svc, svc_pg, -1)\n",
    "logger.info(gs_svc.cv_results_)\n",
    "gs_svc.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    }
   ],
   "source": [
    "cell_log(16, \"Logistic regression\")\n",
    "gs_log= fit_return_best_model(log_reg, log_pg, -1)\n",
    "logger.info(gs_log.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"grid search SVC cv results\")\n",
    "logger.info(gs_svc.cv_results_)\n",
    "logger.info(\"grid search logistic cv results\")\n",
    "logger.info(gs_log.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
